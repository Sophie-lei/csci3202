{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 3202, Fall 2021\n",
    "\n",
    "# Wednesday September 22 & Friday September 24\n",
    "\n",
    "# Hill climbing and Simulated Annealing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's load a few packages that we might find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"http://1.bp.blogspot.com/-mWUxSF7q_JY/Vbd84OcwaSI/AAAAAAAA7No/5iT8gMZBHw8/s1600/seilschaft2---helliventures-joachimhellinger.jpg=\" width=\"300\"/>\n",
    "\n",
    "\n",
    "\n",
    "## Problem 1: Hill-climbing\n",
    "\n",
    "The over-arching goal here is to maximize some objective function.  You can also look at this as minimizing some kind of a loss... and you will!\n",
    "\n",
    "In many applications, the objective function might turn out to be a Gaussian function, such as this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_objective(state):\n",
    "    return stats.norm.pdf(x=state, loc=5, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the this objective function is just taking in some value $\\texttt{state}$ and returning the value of the normal probability density function, centered at $\\texttt{loc} = \\mu = 5$ and with standard deviation $\\texttt{scale} = \\sigma = 2$:\n",
    "$$f(\\texttt{state}) = \\dfrac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\dfrac{(\\texttt{state}-\\mu)^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For good measure, let's plot this thing up and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5,15,0.1)\n",
    "f = [gaussian_objective(state) for state in x]\n",
    "\n",
    "plt.plot(x,f)\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Objective function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat.\n",
    "\n",
    "<br>\n",
    "\n",
    "The first order of business if we want to maximize some objective function using the **local search** techniques we just learned will be to set up a class structure to make this easier.\n",
    "\n",
    "If we do this in a general enough way for **hill-climbing** (this first part), we will only need to modify a few things to tackle a trickier problem using **simulated annealing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### (1a)  A class structure to solve problems\n",
    "\n",
    "So first, let's define a class to keep track of the `state`.  This is the quantity we want to adjust in order to optimize the objective function.  That sentence indicates the two values we really need to keep track of for a `state`:\n",
    "1. the value of `state`\n",
    "2. the value of the `objective_function` when evaluated at `state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class state:\n",
    "        # we need to be able to keep track of states and their associated\n",
    "        # objective function values\n",
    "        def __init__(self,node,value):\n",
    "            self.node=node\n",
    "            self.value=value\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define our problem.  This should be entirely self-contained. We need to feed the `hill_climb` optimization routine below a fairly generic problem description, so we can easily feed in different problems.\n",
    "\n",
    "**The goal** with this class structure is to have everything that is **problem-specific** sent into the hill-climbing optimization/local search be self-contained within the `problem` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class problem:\n",
    "    def __init__(self, initial,objective_function,stepsize):\n",
    "        self.initial_state=initial\n",
    "        self.current.state = initial\n",
    "        self.objective_function=object_function\n",
    "        self.stepsize=stepsize\n",
    "        \n",
    "    def move(self):\n",
    "        all_moves=[]\n",
    "        all_moves.append(self.current_state.node-stepsize)\n",
    "        all_moves.append(self.current_state.node+stepsize)\n",
    "        return all_moves\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    # We want to include everything that defines the problem here:\n",
    "    # - initial state\n",
    "    # - current state\n",
    "    # - what is the objective function we're trying to maximize/minimize?\n",
    "    # - what are the choices of action that we have?\n",
    "    # - what do we need to know to select our action?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can turn our Hill-climbing pseudocode into real code, that takes only two arguments and returns the `state` that optimizes the `objective_function`.  Note that the return can be done implicitly by manipulating the current state within our `problem`, or we could code it up as an explicit output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climb(problem, n_iter):\n",
    "    for k in range(n_iter):\n",
    "        nextMove, nextValue=problem.best_move()\n",
    "        if nextValue<=problem.current_state.value:\n",
    "            return problem.current_state\n",
    "        \n",
    "        problem.current_state.node=nextMove\n",
    "        problem.current_state.value=nextValue\n",
    "    print(\"reached max iterations\")\n",
    "    return False\n",
    "\n",
    "    \n",
    "    # for t in some number of iterations:\n",
    "    #     1. get a list of our available moves\n",
    "    #     2. which move optimizes the objective function?\n",
    "    #     3. do that move; update our status\n",
    "    #     4. possible goal/convergence check\n",
    "\n",
    "class problem_hillclimb(problem):\n",
    "    def best_move(self):\n",
    "        all_moves = self.moves()\n",
    "        obj_func=(self.objective_function(move) for move in all_moves)\n",
    "        best = all_moves[max(zip(obj_func,range(len(obj_func))))[1]]\n",
    "        return best, np.max(obj_func)\n",
    "        \n",
    "        \n",
    "        # return the best move possible from the current_state'''\n",
    "        # what moves are possible?\n",
    "        # what is objective function for each of them?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### (1b)  Ready to solve!\n",
    "\n",
    "Let's start by creating an `initial_state` for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state=state[node=1,value=gaussian_objective[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need an instance of our `problem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_problem=problem_hillclimb[initial=initial_states, objective_function=gaussian_objective,stepsize=0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can turn out `hill_climb` algorithm loose on this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut=hill_cilmb(gaussian_problem,n,niter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cut,node,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A couple extensions\n",
    "\n",
    "That's good and all, but that particular objective function was just a single univariate Gaussian.  It turns out that the real world is tougher than that.  So let's tackle some tougher problems, shall we?\n",
    "\n",
    "\n",
    "\n",
    "### (1c) Minimization\n",
    "\n",
    "First, it might be the case that we want to ***minimize*** an objective function instead of maximizing it.  Modify your hill-climbing codes to tackle the problem of minimization.  Note:  this ought to be do-able by modifying a single line of code from above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **define your own** objective function to minimize!  Easy options include concave-up quadratic functions just slapping a $-$ sign into the Gaussian objective function defined above.  Then turn your descent algorithm loose on the minimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (1d)  Random restarts\n",
    "\n",
    "That single Gaussian actually covers many real-world applications of optimization and local search, but many other applications lead to \"bumpier\" objective functions.  Suppose you are trying to fit a model to noisy data, and suppose each of your data points has normally-distributed uncertainty.  Then the objective function you would like to minimize could take the form of the sum of several Gaussian distributions, like so:\n",
    "\n",
    "$$f(\\texttt{state}) = \\dfrac{1}{\\sqrt{2\\pi}\\sigma} \\left(e^{-\\dfrac{(\\texttt{state}-\\mu_0)^2}{2\\sigma^2}} + \n",
    "e^{-\\dfrac{(\\texttt{state}-\\mu_1)^2}{2\\sigma^2}} + \n",
    "e^{-\\dfrac{(\\texttt{state}-\\mu_2)^2}{2\\sigma^2}} + \n",
    "e^{-\\dfrac{(\\texttt{state}-\\mu_3)^2}{2\\sigma^2}} + \n",
    "e^{-\\dfrac{(\\texttt{state}-\\mu_4)^2}{2\\sigma^2}}\\right)$$\n",
    "\n",
    "Here, $\\mu_i$ denotes the data points you have, $\\sigma$ is assumed to be an uncertainty shared by all of them, and $\\texttt{state}$ is your model's output, which you want to fit through those data points.\n",
    "\n",
    "If we let $\\sigma=1$, $\\mu_0 = 0$, $\\mu_1 = 2.1$, $\\mu_2 = 4$, $\\mu_3 = 4$ and $\\mu_4 = 8$, then we end up with the following objective function, `several_gaussian_objective(state)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def several_gaussian_objective(state):\n",
    "    locs = [0,2.1,4,4,8] # centers of a bunch of normal distributions\n",
    "    objective_value = 0\n",
    "    # objective function is actually just the sum of a bunch of normal pdfs\n",
    "    for loc in locs:\n",
    "        objective_value += stats.norm.pdf(state, loc=loc, scale=1)\n",
    "    return objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot up this new objective function as a function of `state`.  What do you notice?  Will our \"vanilla\" hill-climbing routine successfully climb the hill and maximize this objective function for *any* initial state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(start=-5, stop=15, step=0.1)\n",
    "fx = [several_gaussian_objective(xk) for xk in x]\n",
    "plt.plot(x, fx, lw=2)\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Objective function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can check about where the global maximum is fairly easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(zip(fx, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify our vanilla hill-climbing solution approach from **(1b)** to include 500 random restarts for the initial state.\n",
    "\n",
    "The following code will draw `n_restarts` random samples from the range $[0, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_restarts = 500\n",
    "sample = np.random.random(size=n_restarts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify that to draw instead from the range $[-2, 10)$.  Use those samples to create an **ensemble** of the values of `state` for which the objective function is maximized.  Plot a histogram of them, and make a conclusion about what the \"best guess\" for the maximal `state` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_restarts = 500\n",
    "max_found = []\n",
    "range_init = [-2, 10]\n",
    "initial_values = np.random.random(size=n_restarts)*np.diff(range_init)+range_init[0]\n",
    "for n in range(n_restarts):\n",
    "    initial_state = state(node=initial_values[n], value=several_gaussian_objective(initial_values[n]))\n",
    "    gaussian_problem = problem_hillclimb(initial=initial_state, objective_function=several_gaussian_objective, stepsize=0.1)\n",
    "    out = hill_climb(gaussian_problem, n_iter=500)\n",
    "    max_found.append(out.node)\n",
    "    \n",
    "plt.hist(max_found)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://www.metalsupermarkets.com/wp-content/uploads/2015/09/Heat-Treating-Furnace-2.jpg\" width=\"300\"/>\n",
    "\n",
    "\n",
    "\n",
    "## Problem 2: Simulated annealing\n",
    "\n",
    "\n",
    "\n",
    "### (2a) \n",
    "\n",
    "First, we need to either create a new class for a simulated annealing `problem`, or sub-class our `problem` class from earlier. That shouldn't be too bad - the main difference is that instead of the best move at any given point, we need to select a random one.\n",
    "\n",
    "In addition to the `objective_function` argument during construction, we also ought to include the `schedule_function` for the temperature updates as time goes on (which moderate how likely we are to take sub-optimal steps). (We will define that one next!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that here I've sub-classed `problem`. In general, it might make more sense to just add more methods to a generic problem class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (2b)  Find a temperature schedule\n",
    "\n",
    "Now, we need to actually write our code for the simulated annealing algorithm.  That's a bit more involved than the hill-climbing.\n",
    "\n",
    "The trickiest part is deciding the form for (1) the temperature/time schedule $T(t)$ ($T$ is temperature, $t$ is time), and (2) the accept/reject probability as a function of temperature and the difference in model performance between our current and proposed moves, $\\Delta E$.\n",
    "\n",
    "First, let's play around with the **temperature schedule**.  A typical choice might look like:\n",
    "\n",
    "$$T(t) = \\dfrac{C}{(t+1)^p}$$\n",
    "\n",
    "where $C$ and $p$ are some constants you can tune. The +1 in the denominator is to avoid divide-by-0 situations. \n",
    "\n",
    "Now a typical choice for the probability of accepting a move, based on $\\Delta E = f(\\text{current state}) - f(\\text{proposed state})$ (where $f$ is the objective function that we want to *minimize* here) is:\n",
    "\n",
    "$$p_{accept} = \\exp{\\left(\\dfrac{\\Delta E}{T(t)}\\right)}$$\n",
    "\n",
    "Note that:\n",
    "1. if we wanted instead to *maximize* $f$, we just need to throw a $-$ sign in front of $\\Delta E$, and\n",
    "2. if we find that $f(\\text{proposed state}) < f(\\text{current state})$, then $\\Delta E > 0$ and we should accept the move with $p_{accept} = 1$.\n",
    "\n",
    "That form for $p_{accept}$ is based loosely off of Newton's Law of Cooling and good old-fashioned thermodynamics.  Say what you will about Newton ([he was a jerk](https://jencyclopedic.wordpress.com/2014/04/02/isaac-newton-was-a-dick/)), but his law of cooling is pretty nice.\n",
    "\n",
    "See if you can choose $C$ and $p$ such that the acceptance probability $p_{accept}$ starts near 1 and decreases smoothly to somewhere around 20% for $t$ ranging from 0 to 1,000.\n",
    "For these preliminary tests, let's just assume that $\\Delta E$ is constant at $\\Delta E = -0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = list(range(1000))\n",
    "# Modify next line with new C and p values\n",
    "temperature = [C/(tt+1)**p for tt in time]\n",
    "paccept = [np.exp(-0.2/temp) for temp in temperature]\n",
    "\n",
    "plt.plot(time, paccept)\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with these choices for $C$ and $p$, we can define a `schedule(time)` function for $T(t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(time):\n",
    "    '''some sort of mapping from time to temperature, to represent how we should be \n",
    "    \"cooling off\" - that is, accepting wacky solutions with lower and lower probability'''\n",
    "    C = #\n",
    "    p = #\n",
    "    \n",
    "    \n",
    "    return temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (2c)  Define our simulated annealing algorithm\n",
    "\n",
    "Now that we have a temperature updating `schedule`, which defines how we accept/reject proposed moves for our simulated annealing algorithm, we can actually turn our pseudocode into real code!\n",
    "\n",
    "Let's write a `simulated_annealing` algorithm. Similar to the `hill_climbing` one above, we should take as arguments only the `problem` statement and maybe one other argument for the number of iterations to run the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(problem, n_iter):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (2d) Let's solve that problem from class!\n",
    "\n",
    "\n",
    "You know that plot in class of an example objective function we wanted to use simulated annealing to minimize?\n",
    "\n",
    "Well...  it's just the `several_gaussian_objective` from **(1d)** but ***upside-down!!!***\n",
    "\n",
    "(You should feel free to rename this function...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_such_a_mystery_anymore_objective(state):\n",
    "    locs = [0,2.1,4,4,8] # centers of a bunch of normal distributions\n",
    "    objective_value = 0\n",
    "    # objective function is actually just the sum of a bunch of normal pdfs\n",
    "    for loc in locs:\n",
    "        objective_value += stats.norm.pdf(state, loc=loc, scale=1)\n",
    "    return 1-objective_value\n",
    "\n",
    "x = np.arange(start=-5, stop=15, step=0.1)\n",
    "fx = [not_such_a_mystery_anymore_objective(xk) for xk in x]\n",
    "\n",
    "plt.plot(x, fx, c='coral', lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to use our simulated annealing algorithm to solve this problem!\n",
    "1. Define an `initial_state` and declare a relevant `problem`\n",
    "2. Feed these into your simulated annealing algorithm to attempt to find the global minimum\n",
    "\n",
    "If you're having trouble hitting the global minimum, try playing around with different values for:\n",
    "* stepsize (taking tiny steps makes it harder to get out of a local minimum)\n",
    "* schedule (mapping from time to temperature - if you lower the temperature slowly enough, the algorithm *will* find the global minimum with probability approaching 1)\n",
    "* start with initial `state` that you know should lead into the global minimum. Once you are happy that you can reliably optimize starting from there, move away and see how you need to modify the stepsize and/or temperature schedule to keep making it to the minimum.\n",
    "* try using a **random restart** range of initial states, similarly to how we tackled this problem (upside-down) using hill-climbing, and plotting a histogram of the ensemble results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
